# realization_multilayers_neural_networks

Even nowadays we have very handy deep learning framework like Tensorflow, it is important to have a solid 
understanding of several critical concepts like forward, back propagation, activition functions, softmax, loss function......
 In this exercise, we have implemented a basic multi-layers neural networks, its important components includes:
 
1. Activation functions implementation (sigmoid, tanh, relu)
2. forward
3. backward
4. update
5. softmax
6. computeLoss
7. getMiniBatch
8. L1 and L2 regularization
9. Dynamic learning rate

The model is tested my mnist and cifar10. For further more details of this implementation and results, consult [rapport.pdf](https://github.com/mogolola/realization_multilayers_neural_networks/blob/master/rapport.pdf)